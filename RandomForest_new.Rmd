---
title: "RandomForest 2.0"
author: "Eric Jensen"
date: "October 28, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)

library(tidyverse)
library(sf)
library(randomForest)
library(rfUtilities)
library(corrplot)
library(ggthemes)
library(ggpubr)
library(spatstat)
library(caret)
library(gbm)
```

### Wrangle data for modeling
#### Import zonal statistics CSVs and process to prepare for join
```{r}
# Topographic
BioPhys_mean = read_csv('data/GEEZonal_CSVs/Biophysical_Predictors_Mean.csv')
BioPhys_mode = read_csv('data/GEEZonal_CSVs/Biophysical_Predictors_Mode.csv')

# Climate (annual and 30-year mean)
Climate_ann = read_csv('data/GEEZonal_CSVs/Climate_covariates.csv') 
Climate_mean = read_csv('data/GEEZonal_CSVs/Climate_Predictors_Mean.csv')

# Soil
Soil = read_csv('data/GEEZonal_CSVs/Soil_Predictors.csv')

# Remote Sensing
RemSens = read_csv('data/GEEZonal_CSVs/RS_Predictors.csv')
RemSens_clust = read_csv('data/GEEZonal_CSVs/RS_clust_predictors.csv') %>% drop_na()
RemSens_specDiv_clean = read_csv('data/GEEZonal_CSVs/Spectral_Div_Predictors.csv') %>% drop_na()

# Cheatgrass
Cheatgrass = read_csv('data/GEEZonal_CSVs/Cheatgrass_Predictor.csv')

# Fire
Fire_mtbs = read_csv('data/GEEZonal_CSVs/Fire_Predictors.csv')
Fire_dnbr = read_csv('data/GEEZonal_CSVs/dNBR_Predictors.csv')
Fire_rdnbr = read_csv('data/GEEZonal_CSVs/RdNBR_Predictors.csv')
```

Calculate proportion of distinct classes to number of cells in unsupervised classification data
```{r}
RemSens_clust = RemSens_clust %>%
  mutate(k25_prop = kmeans25_distcount/kmeans25_count) %>%
  mutate(k50_prop = kmeans50_distcount/kmeans50_count) %>%
  mutate(k100_prop = kmeans100_distcount/kmeans100_count) %>%
  mutate(k200_prop = kmeans200_distcount/kmeans200_count) %>%
  mutate(k500_prop = kmeans500_distcount/kmeans200_count) %>%
  dplyr::select(-c('kmeans25_count','kmeans50_count','kmeans100_count','kmeans200_count', 'kmeans500_count','CountNorm', contains('histogram'))) %>%
  filter(k25_prop != 'inf')
```

Clean the imported predictor CSVs
```{r}
# Function to clean most of the dataframes
clean_df <- function(df){
  df %>%
  dplyr::select(-c(PlotID, Program, .geo, SpeciesN, VisitDate, VisitYear,1))}

BioPhys_mode_clean <- clean_df(BioPhys_mode) %>% mutate(landform = mode) %>% dplyr::select(-mode) %>% drop_na()
BioPhys_mean_clean <- clean_df(BioPhys_mean)%>% drop_na()
Climate_ann_clean <- clean_df(Climate_ann) %>% drop_na()
Climate_mean_clean <- clean_df(Climate_mean) %>% drop_na()
Soil_clean <- clean_df(Soil) %>% drop_na()
RemSens_clust_clean <- clean_df(RemSens_clust) %>% dplyr::select(-c(contains('_distcount'))) %>% drop_na()
Fire_clean <- clean_df(Fire_mtbs) %>% dplyr::select(-c(YearsOfMTBS,LastFire,MaxSev,RecentSev)) %>% replace(., is.na(.), 0)
dnbr_clean <- clean_df(Fire_dnbr) %>% dplyr::select(c(PrimaryKey, dnbr_MaxSev = MaxSev, dnbr_RecentSev = RecentSev)) %>% replace(., is.na(.), 0)
rdnbr_clean <- clean_df(Fire_rdnbr) %>% dplyr::select(c(PrimaryKey, rdnbr_MaxSev = MaxSev, rdnbr_RecentSev = RecentSev)) %>% replace(., is.na(.), 0)
Cheatgrass_clean <- clean_df(Cheatgrass) %>% replace(., is.na(.), 0) %>% dplyr::select(c(PrimaryKey, Cheatgrass = median))

# Clean the remote sensing dataframe
RemSens_clean <- RemSens %>%
  dplyr::select(-c(.geo, VisitYear,1, contains('_sd'),contains('_cv')))

remove(BioPhys_mean,BioPhys_mode,Climate_ann,Climate_mean,Soil,Fire_mtbs, Fire_dnbr, Fire_rdnbr,RemSens,RemSens_clust, clean_df, Cheatgrass)
```

Join the dataframes together for modeling
```{r}
# All predictors except individual bands (removed)
# Clean up miscellaneous details
Predictors_all <- BioPhys_mean_clean %>%
  left_join(BioPhys_mode_clean, by = 'PrimaryKey') %>%
  left_join(RemSens_clean, by = 'PrimaryKey') %>%
  left_join(RemSens_clust_clean, by = 'PrimaryKey') %>%
  left_join(RemSens_specDiv_clean, by = 'PrimaryKey') %>%
  left_join(Soil_clean, by = 'PrimaryKey') %>%
  left_join(Fire_clean, by = 'PrimaryKey') %>%
  left_join(dnbr_clean, by = 'PrimaryKey') %>%
  left_join(Climate_ann_clean, by = 'PrimaryKey') %>%
  left_join(Climate_mean_clean, by = 'PrimaryKey') %>%
  left_join(Cheatgrass_clean, by = 'PrimaryKey') %>%
  setNames(paste0('p.', names(.))) %>% #add p prefix to denote predictors
  dplyr::rename(PrimaryKey = p.PrimaryKey) %>%
  dplyr::select(-c(p.SpeciesN,starts_with('p.B'))) #%>% # revert names of non-predictors
  unique() %>%
  drop_na()

# Left out dnbr because of an issue with the primary key in the dataframe:   left_join(rdnbr_clean, by = 'PrimaryKey') %>%  
  
remove(dnbr_clean,rdnbr_clean, Cheatgrass_clean, RemSens_specDiv_clean, Fire_clean, Soil_clean, RemSens_clean, RemSens_clust_clean, BioPhys_mean_clean, BioPhys_mode_clean,Climate_mean_clean,Climate_ann_clean)
```

Join the predictors and responses together
```{r}
### Import Species Diversity data
Responses = read_csv('data/SpectralDiversity_CSVs/Allplots.csv') %>% dplyr::select(c(PrimaryKey,r.SpeciesN = SpeciesN))

# Function in case I want to build multiple tables later
BuildModelTable = function(preds){
  table <- preds %>%
            full_join(Responses, 'PrimaryKey') 
  return(table)}

# All predictors except individual bands
ModelTable = BuildModelTable(Predictors_all) %>% 
  mutate(p.landform = as.factor(p.landform)) %>%
  drop_na()

remove(Predictors_all)
```

Assess correlations of predictor variables
```{r}
# Exclude non-numeric predictors
ModelTable_cor <- dplyr::select_if(ModelTable, is.numeric) %>%
  dplyr::select(starts_with('p.')) %>%
  as.matrix() %>%
  cor(method = "s")

# Plot the correlations
corrplot(ModelTable_cor)

remove(ModelTable_cor)
```

Divide modeling dataframe into training set and test set
```{r}
# Create validation set using 25% of data and modeling set with remaining 75% of data
set.seed(10)
model_val_wKey <- sample_frac(ModelTable, size = .25, replace = FALSE)
model_train <- ModelTable %>%
  mutate(drop = ModelTable$PrimaryKey %in% model_val$PrimaryKey) %>%
  filter(drop == FALSE) %>%
  select(-drop)

model_train <- model_train %>% dplyr::select(-PrimaryKey)
model_val <- model_val %>% dplyr::select(-PrimaryKey)
remove(ModelTable,Responses,BuildModelTable)
```


### Random Forest Modeling
Random forest variable selection
```{r}
# Perform Random Forest variable selection
RFsel_All = rf.modelSel(xdata = model_train %>% dplyr::select(starts_with('p.')), ydata = model_train$r.SpeciesN, r = c(0.1, 0.2, 0.5, 0.7, 0.9)) 

#Assess outputs from species richness model
plot(RFsel_All)
```

```{r}
################################################################################
########################### Skipping this for now ##############################

# Function to process the rf.modelSel() objects
Process_ModelSel = function(rfsel){
    rfsel <- cbind(rownames(rfsel$sel.importance), rfsel$sel.importance)
    rownames(rfsel) <- NULL
    colnames(rfsel) <- c("name", "imp")
    return(rfsel)}

RFsel_ALL_SR_ready = Process_ModelSel(RFsel_All_SR)
RFsel_NoBands_SR_ready = Process_ModelSel(RFsel_NoBands_SR)

###########################################################
######## Convert these to more succinct functions #########

# Order the dataframe by variable importance
RFsel_ALL_SR_ready <- RFsel_ALL_SR_ready[order(-RFsel_ALL_SR_ready$imp),]
RFsel_NoBands_SR_ready <- RFsel_NoBands_SR_ready[order(-RFsel_NoBands_SR_ready$imp),]

# Get list of names of top 30 predictors for each model
RFsel_ALL_SR_names <- RFsel_ALL_SR_ready$name[1:nrow(RFsel_ALL_SR_ready)]
RFsel_NoBands_SR_names <- RFsel_NoBands_SR_ready$name[1:nrow(RFsel_NoBands_SR_ready)]

# drop columns that are not as important based on rfmodelsel--columns not in list of names
RFsel_ALL_SR_cov <- Preds_All[,as.character(RFsel_ALL_SR_names)] #[-c(4,5,6,9,8,7)]]
RFsel_NoBands_SR_cov <- Preds_NoBands[,as.character(RFsel_NoBands_SR_names)]

#Too many GD object--get rid of some
remove(RFsel_ALL_SR_ready,RFsel_NoBands_SR_ready,Predictors_all,Predictors_noBands,BuildModelTable,Process_ModelSel,subset_preds,subset_resp)
```

Assess correlation between model predictors
```{r}
#Consider removing highly correlated variables
```

Run random forest models
```{r}
### Generate random number to set seed
# sample(1:1000000,1)
rf_seed = 517953
set.seed(rf_seed)

# Run tuning function
rf_all_tune <-tuneRF(y=model_train$r.SpeciesN, x = model_train %>% dplyr::select(-c(r.SpeciesN)), ntreeTry=300)

# Get the mtry value that minimizes error
mtry_all_opt <- rf_all_tune[, 'mtry'][which.min(rf_all_tune[,'OOBError'])]

# Apply the model using the optimal mtry tuning parameter
ALL_rf_model = randomForest(r.SpeciesN ~ ., data = model_train, importance = TRUE, ntree = 200, mtry = mtry_all_opt)

varImpPlot(ALL_rf_model)

# Use the strongest model going forward
ALL_rf_model
plot(ALL_rf_model)
```

**Tuning a Random Forest via tree depth**  
From the Data Camp *Machine learning with decision trees* course
```{r}
# Establish a list of possible values for mtry, nodesize and sampsize
mtry <- seq(4, ncol(ModelTable) * 0.8, 12)
nodesize <- seq(3, 8, 2)
sampsize <- nrow(ModelTable) * c(0.7, 0.8)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)

# Create an empty vector to store OOB error values
rsq_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {
    print(i)
    # Train a Random Forest model
    model <- randomForest(formula = r.SpeciesN ~ ., 
                          data = ModelTable,
                          mtry = hyper_grid$mtry[i],
                          nodesize = hyper_grid$nodesize[i],
                          sampsize = hyper_grid$sampsize[i],
                          ntree = 200)
                          
    # Store OOB error for the model  
    rsq_err[i] <- model$rsq[length(model$rsq)]
    print(rsq_err[i])
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.max(rsq_err)
print(hyper_grid[opt_i,])
```

Assess random forest model on the independent validation set
```{r}
# Predict on validation set
rf_preds <- predict(object = ALL_rf_model, newdata = model_val %>% dplyr::select(-c(r.SpeciesN)))

# Bind prediction to actual data
rf_val_preds <- tibble(Predicted = rf_preds, 
                       Response = model_val$r.SpeciesN,
                       PrimaryKey = model_val_wKey$PrimaryKey) %>%
                  mutate(Error = abs(Predicted - Response)) %>%
                  mutate(SqError = (Predicted - Response)^2)

# Calculate validation stats
postResample(rf_val_preds$Prediction, val_preds$Response)
rf_rmse <- postResample(rf_val_preds$Prediction, rf_val_preds$Response)[[1]] %>% round(4)
rf_rsq <- postResample(rf_val_preds$Prediction, rf_val_preds$Response)[[2]] %>% round(4)
```

### Boosted trees
Investigate boosted regression tree approach
Used same proceedure as Machine learning with tree-based models in R course on DataCamp
```{r}
set.seed(rf_seed)

# Build GBM model
ALL_gbm_model <- gbm(formula = r.SpeciesN ~ .,
                     distribution = 'poisson',
                     data = model_train,
                     n.trees = 1000)
# Evaluate predictors
print(ALL_gbm_model)
summary(ALL_gbm_model)

# Generate predictions on test set // scale to response rather than on log scale (default for Poisson)
gbm_preds <- predict(object = ALL_gbm_model,
                     newdata = model_val %>% dplyr::select(-r.SpeciesN),
                     n.trees = 1000,
                     type = "response")

range(model_val$r.SpeciesN)
range(gbm_preds)
range(rf_preds)

# Tuning // Early stopping --------------------
# Optimal ntree estimate based on OOB
ntree_opt_oob <- gbm.perf(object = ALL_gbm_model, 
                          method = 'OOB', 
                          oobag.curve = TRUE)

# Train a CV GBM model
set.seed(rf_seed)
ALL_gbm_model_cv <- gbm(formula = r.SpeciesN ~ .,
                     distribution = 'poisson',
                     data = model_train,
                     n.trees = 4000,
                     cv.folds = 5)

# Optimal ntree estimate based on CV
ntree_opt_cv <- gbm.perf(object = ALL_gbm_model_cv, 
                         method = 'cv')

# Compare the estimates                         
print(paste0("Optimal n.trees (OOB Estimate): ", ntree_opt_oob))                         
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv))

# Generate predictions on the test set using ntree_opt_cv number of trees
gbm_preds2 <- predict(object = ALL_gbm_model_cv, 
                  newdata = model_val,
                  n.trees = ntree_opt_cv,
                  type = "response")  

# Bind prediction to actual data
gbm_val_preds <- as_tibble(cbind(model_val$r.SpeciesN, gbm_preds2)) %>% dplyr::select(c(Response = V1, Prediction = gbm_preds2))

# Calculate validation stats
postResample(gbm_val_preds$Prediction, gbm_val_preds$Response)
gbm_rmse <- postResample(gbm_val_preds$Prediction, gbm_val_preds$Response)[[1]] %>% round(4)
gbm_rsq <- postResample(gbm_val_preds$Prediction, gbm_val_preds$Response)[[2]] %>% round(4)
```

Plot the predicted data vs. the observed data for validation set of RandomForest
```{r}
# Plot random forest
rf_rsq_grob <- text_grob(paste("R-squared =", as.character(rf_rsq)), x = .15, y = .95)
rf_rmse_grob <- text_grob(paste("RMSE =", as.character(rf_rmse)), x = .13, y = .9)

ggplot(rf_val_preds, aes(x=Response, y = Prediction)) +
  geom_point(alpha=.2, color = 'blue',  shape = 16) +
  geom_smooth(method='lm',formula=y~x, color = 'red') +
  geom_abline(intercept = 0, slope = 1, cex = 1) +
  labs(x = "Observed diversity", y = "Predicted diversity", title = "Model predictions against field observations") +
  annotation_custom(rf_rsq_grob) +
  annotation_custom(rf_rmse_grob) +
  scale_x_continuous(limits = c(0,60), breaks = seq(0,60,10)) + 
  scale_y_continuous(limits = c(0,60), breaks = seq(0,60,10)) +
  theme_few()

# Plot gbm
gbm_rsq_grob <- text_grob(paste("R-squared =", as.character(gbm_rsq)), x = .15, y = .95)
gbm_rmse_grob <- text_grob(paste("RMSE =", as.character(gbm_rmse)), x = .13, y = .9)

ggplot(gbm_val_preds, aes(x=Response, y = Prediction)) +
  geom_point(alpha=.2, color = 'blue',  shape = 16) +
  geom_smooth(method='lm',formula=y~x, color = 'red') +
  geom_abline(intercept = 0, slope = 1, cex = 1) +
  labs(x = "Observed diversity", y = "Predicted diversity", title = "Model predictions against field observations") +
  annotation_custom(gbm_rsq_grob) +
  annotation_custom(gbm_rmse_grob) +
  scale_x_continuous(limits = c(0,60), breaks = seq(0,60,10)) + 
  scale_y_continuous(limits = c(0,60), breaks = seq(0,60,10)) +
  theme_few()
```

Assess errors spatially
```{r}
# Import spatial data
AIM_spatial <- read_sf('data/AIM_PlotOutput/AIM_all_2.shp') %>% 
  st_transform(crs = 4326)

# Join validation set predictions to spatial data
rf_val_spatial <- st_as_sf(left_join(rf_val_preds, AIM_spatial, 'PrimaryKey'))

ggplot()+
  geom_sf(rf_val_spatial, mapping =aes(fill = SqError, color = SqError, cex = SqError))+
  scale_colour_viridis_c() +
  scale_fill_viridis_c()
```

