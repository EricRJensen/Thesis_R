---
title: "RandomForest 2.0"
author: "Eric Jensen"
date: "October 28, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(randomForest)
library(rfUtilities)
library(corrplot)
library(ggthemes)
library(egg)
library(ggpubr)
library(spatstat)
```

### Wrangle data for modeling
#### Import zonal statistics CSVs and process to prepare for join
```{r}
# Topographic
BioPhys_mean = read_csv('data/GEEZonal_CSVs/Biophysical_Predictors_Mean.csv')
BioPhys_mode = read_csv('data/GEEZonal_CSVs/Biophysical_Predictors_Mode.csv')

# Climate (annual and 30-year mean)
Climate_ann = read_csv('data/GEEZonal_CSVs/Climate_covariates.csv') 
Climate_mean = read_csv('data/GEEZonal_CSVs/Climate_Predictors_Mean.csv')

# Soil
Soil = read_csv('data/GEEZonal_CSVs/Soil_Predictors.csv')

# Remote Sensing
RemSens = read_csv('data/GEEZonal_CSVs/RS_Predictors.csv')
RemSens_clust = read_csv('data/GEEZonal_CSVs/RS_clust_predictors.csv')
RemSens_specDiv_clean = read_csv('data/GEEZonal_CSVs/Spectral_Div_Predictors.csv') %>% drop_na()

# Cheatgrass
Cheatgrass = read_csv('data/GEEZonal_CSVs/Cheatgrass_Predictor.csv')

# Fire
Fire_mtbs = read_csv('data/GEEZonal_CSVs/Fire_Predictors.csv')
Fire_dnbr = read_csv('data/GEEZonal_CSVs/dNBR_Predictors.csv')
Fire_rdnbr = read_csv('data/GEEZonal_CSVs/RdNBR_Predictors.csv')
```

Calculate proportion of distinct classes to number of cells in unsupervised classification data
```{r}
RemSens_clust = RemSens_clust %>%
  mutate(k25_prop = kmeans25_distcount/kmeans25_count) %>%
  mutate(k50_prop = kmeans50_distcount/kmeans50_count) %>%
  mutate(k100_prop = kmeans100_distcount/kmeans100_count) %>%
  mutate(k200_prop = kmeans200_distcount/kmeans200_count) %>%
  mutate(k500_prop = kmeans500_distcount/kmeans200_count) %>%
  dplyr::select(-c('kmeans25_count','kmeans50_count','kmeans100_count','kmeans200_count', 'kmeans500_count','CountNorm', contains('histogram'))) %>%
  filter(k25_prop != 'inf')
```

Clean the imported predictor CSVs
```{r}
# Function to clean most of the dataframes
clean_df <- function(df){
  df %>%
  dplyr::select(-c(PlotID, Program, .geo, SpeciesN, VisitDate, VisitYear,1))}

BioPhys_mode_clean <- clean_df(BioPhys_mode) %>% mutate(landform = mode) %>% dplyr::select(-mode) %>% drop_na()
BioPhys_mean_clean <- clean_df(BioPhys_mean)%>% drop_na()
Climate_ann_clean <- clean_df(Climate_ann) %>% drop_na()
Climate_mean_clean <- clean_df(Climate_mean) %>% drop_na()
Soil_clean <- clean_df(Soil) %>% drop_na()
RemSens_clust_clean <- clean_df(RemSens_clust) %>% dplyr::select(-c(contains('_distcount'))) %>% drop_na()
Fire_clean <- clean_df(Fire_mtbs) %>% dplyr::select(-c(YearsOfMTBS,LastFire,MaxSev,RecentSev)) %>% replace(., is.na(.), 0)
dnbr_clean <- clean_df(Fire_dnbr) %>% dplyr::select(c(PrimaryKey, dnbr_MaxSev = MaxSev, dnbr_RecentSev = RecentSev)) %>% replace(., is.na(.), 0)
rdnbr_clean <- clean_df(Fire_rdnbr) %>% dplyr::select(c(PrimaryKey, rdnbr_MaxSev = MaxSev, rdnbr_RecentSev = RecentSev)) %>% replace(., is.na(.), 0)
Cheatgrass_clean <- clean_df(Cheatgrass) %>% replace(., is.na(.), 0) %>% dplyr::select(c(PrimaryKey, Cheatgrass = median))

# Clean the remote sensing dataframe
RemSens_clean <- RemSens %>%
  dplyr::select(-c(.geo, VisitYear,1, contains('_sd'),contains('_cv')))

remove(BioPhys_mean,BioPhys_mode,Climate_ann,Climate_mean,Soil,Fire_mtbs, Fire_dnbr, Fire_rdnbr,RemSens,RemSens_clust, clean_df, Cheatgrass)
```

Join the dataframes together for modeling
```{r}
# All predictors except individual bands (removed)
# Clean up miscellaneous details
Predictors_all <- BioPhys_mean_clean %>%
  left_join(BioPhys_mode_clean, by = 'PrimaryKey') %>%
  left_join(RemSens_clean, by = 'PrimaryKey') %>%
  left_join(RemSens_clust_clean, by = 'PrimaryKey') %>%
  left_join(RemSens_specDiv_clean, by = 'PrimaryKey') %>%
  left_join(Soil_clean, by = 'PrimaryKey') %>%
  left_join(Fire_clean, by = 'PrimaryKey') %>%
  left_join(dnbr_clean, by = 'PrimaryKey') %>%
  left_join(rdnbr_clean, by = 'PrimaryKey') %>%
  left_join(Climate_ann_clean, by = 'PrimaryKey') %>%
  left_join(Climate_mean_clean, by = 'PrimaryKey') %>%
  left_join(Cheatgrass_clean, by = 'PrimaryKey') %>%
  setNames(paste0('p.', names(.))) %>% #add p prefix to denote predictors
  dplyr::rename(PrimaryKey = p.PrimaryKey) %>%
  dplyr::select(-c(p.SpeciesN,starts_with('p.B'))) %>% # revert names of non-predictors
  unique()

remove(dnbr_clean,rdnbr_clean, Cheatgrass_clean, RemSens_specDiv_clean, Fire_clean, Soil_clean, RemSens_clean, RemSens_clust_clean, BioPhys_mean_clean, BioPhys_mode_clean,Climate_mean_clean,Climate_ann_clean)
```

Join the predictors and responses together
```{r}
### Import Species Diversity data
Responses = read_csv('data/SpectralDiversity_CSVs/Allplots.csv') %>% dplyr::select(c(PrimaryKey,r.SpeciesN = SpeciesN))

# Function in case I want to build multiple tables later
BuildModelTable = function(preds){
  table <- preds %>%
            full_join(Responses, 'PrimaryKey') 
  return(table)}

# All predictors except individual bands
ModelTable = BuildModelTable(Predictors_all) %>% 
  dplyr::select(-c(PrimaryKey)) %>% 
  mutate(p.landform = as.factor(p.landform)) %>% 
  drop_na()

remove(Predictors_all,Predictors_noBands)
```

Divide modeling dataframe into training set and test set
```{r}

```


### Random Forest Modeling
Assess correlations of predictor variables
```{r}
# Exclude non-numeric predictors
ModelTable_cor <- dplyr::select_if(ModelTable, is.numeric) %>%
  dplyr::select(starts_with('p.')) %>%
  as.matrix() %>%
  cor(method = "s")

# Plot the correlations
corrplot(ModelTable_cor)

remove(ModelTable_cor)
```

Random forest variable selection
```{r}
# Perform Random Forest variable selection
RFsel_All = rf.modelSel(xdata = ModelTable %>% dplyr::select(starts_with('p.')), ydata = ModelTable$r.SpeciesN, r = c(0.1, 0.2, 0.5, 0.7, 0.9)) 

#Assess outputs from species richness model
plot(RFsel_All)
```

```{r}
################################################################################
########################### Skipping this for now ##############################

# Function to process the rf.modelSel() objects
Process_ModelSel = function(rfsel){
    rfsel <- cbind(rownames(rfsel$sel.importance), rfsel$sel.importance)
    rownames(rfsel) <- NULL
    colnames(rfsel) <- c("name", "imp")
    return(rfsel)}

RFsel_ALL_SR_ready = Process_ModelSel(RFsel_All_SR)
RFsel_NoBands_SR_ready = Process_ModelSel(RFsel_NoBands_SR)

###########################################################
######## Convert these to more succinct functions #########

# Order the dataframe by variable importance
RFsel_ALL_SR_ready <- RFsel_ALL_SR_ready[order(-RFsel_ALL_SR_ready$imp),]
RFsel_NoBands_SR_ready <- RFsel_NoBands_SR_ready[order(-RFsel_NoBands_SR_ready$imp),]

# Get list of names of top 30 predictors for each model
RFsel_ALL_SR_names <- RFsel_ALL_SR_ready$name[1:nrow(RFsel_ALL_SR_ready)]
RFsel_NoBands_SR_names <- RFsel_NoBands_SR_ready$name[1:nrow(RFsel_NoBands_SR_ready)]

# drop columns that are not as important based on rfmodelsel--columns not in list of names
RFsel_ALL_SR_cov <- Preds_All[,as.character(RFsel_ALL_SR_names)] #[-c(4,5,6,9,8,7)]]
RFsel_NoBands_SR_cov <- Preds_NoBands[,as.character(RFsel_NoBands_SR_names)]

#Too many GD object--get rid of some
remove(RFsel_ALL_SR_ready,RFsel_NoBands_SR_ready,Predictors_all,Predictors_noBands,BuildModelTable,Process_ModelSel,subset_preds,subset_resp)
```

Assess correlation between model predictors
```{r}
#Consider removing highly correlated variables
```

Run random forest models
```{r}
### Generate random number to set seed
# sample(1:1000000,1)
rf_seed = 517953
set.seed(rf_seed)

# Run tuning function
rf_all_tune <-tuneRF(y=ModelTable$r.SpeciesN, x = ModelTable %>% dplyr::select(-c(r.SpeciesN)), ntreeTry=300)

# Get the mtry value that minimizes error
mtry_all_opt <- rf_all_tune[, 'mtry'][which.min(rf_all_tune[,'OOBError'])]

# Apply the model using the optimal mtry tuning parameter
ALL_rf_model = randomForest(r.SpeciesN ~ ., data = ModelTable, importance = TRUE, ntree = 200, mtry = mtry_all_opt)

varImpPlot(ALL_rf_model)

# Use the strongest model going forward
ALL_rf_model
plot(ALL_rf_model)
```

**Tuning a Random Forest via tree depth**  
From the Data Camp *Machine learning with decision trees* course
```{r}
# Establish a list of possible values for mtry, nodesize and sampsize
mtry <- seq(4, ncol(ModelTable) * 0.8, 12)
nodesize <- seq(3, 8, 2)
sampsize <- nrow(ModelTable) * c(0.7, 0.8)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)

# Create an empty vector to store OOB error values
rsq_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {
    print(i)
    # Train a Random Forest model
    model <- randomForest(formula = r.SpeciesN ~ ., 
                          data = ModelTable,
                          mtry = hyper_grid$mtry[i],
                          nodesize = hyper_grid$nodesize[i],
                          sampsize = hyper_grid$sampsize[i],
                          ntree = 200)
                          
    # Store OOB error for the model  
    rsq_err[i] <- model$rsq[length(model$rsq)]
    print(rsq_err[i])
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.max(rsq_err)
print(hyper_grid[opt_i,])
```

Assess random forest model on the independent validation set
```{r}

```

Investigate boosted regression tree approach
```{r}

```


Plot the predicted data vs. the observed data
```{r}
# Round for later plotting
All_rf_modelEx <- round(ALL_rf_model$rsq[3000], digits = 4)

All_rf_predicted <- ALL_rf_model$predicted

# plot observed values on the x-axis and predicted values on the y-axis. we are
# looking for these to be correlated (so close to a 1:1 line)
# Plot as Alpha ggplot
All_assess <- dplyr::bind_cols(predict = All_rf_predicted, response = ModelTable$r.SpeciesN)

varAll <- text_grob(paste("Variance explained =", as.character(All_rf_modelEx[1:4]), sep = "\n"), x = .2, y = .9)

ggplot(All_assess, aes(x=response, y = predict)) +
  geom_point(alpha=.1, color = 'blue',  shape = 16) +
  geom_smooth(method='lm',formula=y~x, color = 'red') +
  labs(x = "Observed diversity", y = "Predicted diversity",title="28 variables, 1000 trees") +
  annotation_custom(varAll) +
  theme_few()
gg_NoBands

# calculate r-squared and RMSE
actual = NoBands_assess$response
predicted = NoBands_assess$predict
R2 <- 1 - (sum((actual-predicted)^2)/sum((actual-mean(actual))^2))
library(caret)
rmse <- RMSE(NoBands_assess$predict,NoBands_assess$response)

# model_comp <- egg::ggarrange(gg1000var,gg3000var,gg5000var, nrow = 1)
# annotate_figure(model_comp, top = text_grob("Comparing models with 6 and 14 variables", face = 'bold', size = 18))
```

